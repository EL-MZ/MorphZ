{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating ln(Z) with NumPyro + MorphZ\n",
    "\n",
    "This notebook demonstrates how to compute the Bayesian evidence (log marginal likelihood, **ln Z**) using:\n",
    "\n",
    "- **NumPyro** for posterior sampling (via NUTS)\n",
    "- **MorphZ** for evidence estimation from posterior samples\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EL-MZ/MorphZ/blob/main/examples/numpyro_morphz_lnz.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What We Are Computing\n",
    "\n",
    "Given a model with parameters $\\theta$ and data $y$:\n",
    "\n",
    "Posterior:\n",
    "$$\n",
    "p(\\theta \\mid y) \\propto p(y \\mid \\theta)\\, p(\\theta)\n",
    "$$\n",
    "\n",
    "Evidence (marginal likelihood):\n",
    "$$\n",
    "Z = p(y) = \\int p(y \\mid \\theta)\\, p(\\theta)\\, d\\theta\n",
    "$$\n",
    "\n",
    "We want $\\ln Z$. NumPyro gives posterior samples, and MorphZ estimates $Z$ from those samples plus log-posterior evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install \"jax[cpu]\" numpyro morphz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from numpyro.infer.util import log_density\n",
    "from morphZ import evidence\n",
    "\n",
    "print('jax:', jax.__version__)\n",
    "print('numpyro:', numpyro.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Minimal Toy Model: Gaussian Mean Inference\n",
    "\n",
    "We infer an unknown mean $\\mu$ with known noise $\\sigma$.\n",
    "\n",
    "- Prior: $\\mu \\sim \\mathcal{N}(0, \\tau_0^2)$\n",
    "- Likelihood: $y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# Synthetic dataset\n",
    "n_obs = 40\n",
    "mu_true = 1.25\n",
    "sigma = 0.7\n",
    "tau0 = 2.0\n",
    "y = rng.normal(mu_true, sigma, size=n_obs)\n",
    "\n",
    "print('n_obs =', n_obs)\n",
    "print('sample mean =', y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mean_model(y, sigma, tau0):\n",
    "    mu = numpyro.sample('mu', dist.Normal(0.0, tau0))\n",
    "    numpyro.sample('obs', dist.Normal(mu, sigma), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run NUTS and Collect Posterior Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts = NUTS(gaussian_mean_model)\n",
    "mcmc = MCMC(\n",
    "    nuts,\n",
    "    num_warmup=800,\n",
    "    num_samples=2000,\n",
    "    num_chains=1,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "rng_key = jax.random.PRNGKey(42)\n",
    "mcmc.run(rng_key, y=jnp.asarray(y), sigma=sigma, tau0=tau0)\n",
    "samples = mcmc.get_samples(group_by_chain=False)\n",
    "\n",
    "print('posterior keys:', samples.keys())\n",
    "print('mu sample shape:', np.asarray(samples['mu']).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build a Log Posterior Callable\n",
    "\n",
    "MorphZ needs `lp_fn(sample_vector)` that returns the same log posterior used for sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_log_density_fn(model, model_kwargs):\n",
    "    model_kwargs = jax.tree_util.tree_map(jnp.asarray, model_kwargs)\n",
    "\n",
    "    def _logpost(params):\n",
    "        log_prob, _ = log_density(model, (), model_kwargs, params)\n",
    "        return log_prob\n",
    "\n",
    "    return jax.jit(_logpost)\n",
    "\n",
    "model_kwargs = {\n",
    "    'y': jnp.asarray(y),\n",
    "    'sigma': sigma,\n",
    "    'tau0': tau0,\n",
    "}\n",
    "\n",
    "logpost_fn = build_log_density_fn(gaussian_mean_model, model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pack Samples into a 2D Array\n",
    "\n",
    "MorphZ expects `shape = (n_draws, n_parameters)`. Here we have one parameter (`mu`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_samples = np.asarray(samples['mu'])\n",
    "post_smp = mu_samples[:, None]  # (n_draws, 1)\n",
    "\n",
    "def lp_fn(sample_vec):\n",
    "    params = {'mu': jnp.asarray(sample_vec[0])}\n",
    "    return float(logpost_fn(params))\n",
    "\n",
    "lp = np.array([lp_fn(v) for v in post_smp])\n",
    "\n",
    "print('post_smp shape:', post_smp.shape)\n",
    "print('lp shape:', lp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sanity Check: `lp` vs `lp_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(f'i={i}  precomputed={lp[i]: .6f}  callable={lp_fn(post_smp[i]): .6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Estimate ln(Z) with MorphZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evidence(\n",
    "    post_samples=post_smp,\n",
    "    log_posterior_values=lp,\n",
    "    log_posterior_function=lp_fn,\n",
    "    n_resamples=1000,\n",
    "    thin=2,\n",
    "    kde_fraction=0.6,\n",
    "    bridge_start_fraction=0.5,\n",
    "    max_iter=2000,\n",
    "    tol=1e-4,\n",
    "    morph_type='indep',\n",
    "    kde_bw='silverman',\n",
    "    param_names=['mu'],\n",
    "    output_path='morphz_numpyro_demo',\n",
    "    n_estimations=3,\n",
    "    verbose=False,\n",
    "    plot=False,\n",
    "    show_progress=False,\n",
    ")\n",
    "\n",
    "results = np.asarray(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compare to Analytic ln(Z)\n",
    "\n",
    "For this conjugate Gaussian setup, we can compute exact ln(Z) for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytic_lnz(y, sigma, tau0):\n",
    "    n = y.size\n",
    "    C = (sigma ** 2) * np.eye(n) + (tau0 ** 2) * np.ones((n, n))\n",
    "    sign, logdet = np.linalg.slogdet(C)\n",
    "    if sign <= 0:\n",
    "        raise RuntimeError('Covariance matrix is not positive definite.')\n",
    "    quad = y @ np.linalg.solve(C, y)\n",
    "    return -0.5 * (n * np.log(2 * np.pi) + logdet + quad)\n",
    "\n",
    "lnz_true = analytic_lnz(y, sigma, tau0)\n",
    "lnz_est = results[:, 0]\n",
    "lnz_err = results[:, 1]\n",
    "\n",
    "print('MorphZ ln(Z) per run:', lnz_est)\n",
    "print('MorphZ reported errors:', lnz_err)\n",
    "print(f'MorphZ mean ln(Z): {lnz_est.mean():.6f}')\n",
    "print(f'Analytic ln(Z):     {lnz_true:.6f}')\n",
    "print(f'Absolute difference: {abs(lnz_est.mean() - lnz_true):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "The MorphZ inputs are:\n",
    "\n",
    "- `post_smp`: posterior sample matrix\n",
    "- `lp`: log posterior values at those samples\n",
    "- `lp_fn`: callable log posterior\n",
    "\n",
    "As long as `lp[i] == lp_fn(post_smp[i])`, your evidence estimate is consistent with your sampled posterior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
